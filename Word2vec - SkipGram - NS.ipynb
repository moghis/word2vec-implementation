{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10885,
     "status": "ok",
     "timestamp": 1639733931411,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "TKbGaf5uYpaD",
    "outputId": "68d22c43-a1a2-4daa-cedc-5ea6538d6d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "(100000004,)\n",
      "Word Count is: 29\n",
      "Word Count Sum is 34\n",
      "Sentence Count is: 2\n",
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\n",
      "positive:\n",
      "[(0, [29, 29, 1, 2], [6, 23, 2, 2, 6, 14, 3, 28]), (1, [29, 0, 2, 3], [12, 6, 1, 18, 21, 23, 11, 4]), (2, [0, 1, 3, 4], [10, 13, 6, 20, 10, 11, 14, 10]), (3, [1, 2, 4, 5], [24, 4, 19, 23, 10, 20, 10, 13]), (4, [2, 3, 5, 6], [23, 6, 15, 3, 11, 4, 22, 18]), (5, [3, 4, 6, 7], [10, 10, 20, 13, 9, 10, 4, 6]), (6, [4, 5, 7, 8], [18, 12, 4, 2, 22, 17, 5, 14]), (7, [5, 6, 8, 9], [6, 20, 5, 9, 13, 27, 0, 21]), (8, [6, 7, 9, 10], [6, 25, 2, 18, 10, 10, 5, 22]), (9, [7, 8, 10, 11], [2, 21, 22, 12, 10, 12, 12, 13])]\n",
      "[('fulton', ['county', 'grand'], ['investigation', 'deserves', 'grand', 'grand', 'investigation', 'took', 'jury', 'conducted']), ('county', ['fulton', 'grand', 'jury'], ['evidence', 'investigation', 'county', 'city', 'overall', 'deserves', 'produced', 'said']), ('grand', ['fulton', 'county', 'jury', 'said'], ['election', 'irregularities', 'investigation', 'committee', 'election', 'produced', 'took', 'election']), ('jury', ['county', 'grand', 'said', 'friday'], ['praise', 'said', 'executive', 'deserves', 'election', 'committee', 'election', 'irregularities']), ('said', ['grand', 'jury', 'friday', 'investigation'], ['deserves', 'investigation', 'place', 'jury', 'produced', 'said', 'charge', 'city']), ('friday', ['jury', 'said', 'investigation', 'atlantas'], ['election', 'election', 'committee', 'irregularities', 'primary', 'election', 'said', 'investigation']), ('investigation', ['said', 'friday', 'atlantas', 'recent'], ['city', 'evidence', 'said', 'grand', 'charge', 'presentments', 'friday', 'took']), ('atlantas', ['friday', 'investigation', 'recent', 'primary'], ['investigation', 'committee', 'friday', 'primary', 'irregularities', 'manner', 'fulton', 'overall']), ('recent', ['investigation', 'atlantas', 'primary', 'election'], ['investigation', 'thanks', 'grand', 'city', 'election', 'election', 'friday', 'charge']), ('primary', ['atlantas', 'recent', 'election', 'produced'], ['grand', 'overall', 'charge', 'evidence', 'election', 'evidence', 'evidence', 'irregularities'])]\n",
      "10\n",
      "positive:\n",
      "[(10, [8, 9, 11, 12], [17, 27, 13, 12, 3, 6, 23, 15]), (11, [9, 10, 12, 13], [4, 25, 14, 21, 15, 4, 6, 20]), (12, [10, 11, 13, 14], [18, 4, 18, 27, 17, 3, 21, 2]), (13, [11, 12, 14, 15], [10, 23, 28, 22, 24, 21, 22, 23]), (14, [12, 13, 15, 29], [9, 26, 5, 5, 9, 9, 20, 19]), (15, [13, 14, 29, 29], [4, 11, 12, 16, 3, 9, 22, 22]), (3, [29, 29, 4, 16], [1, 3, 17, 24, 19, 17, 28, 1]), (4, [29, 3, 16, 17], [18, 7, 18, 10, 27, 3, 3, 4]), (16, [3, 4, 17, 18], [3, 27, 9, 27, 16, 10, 5, 12]), (17, [4, 16, 18, 19], [6, 26, 27, 4, 15, 22, 13, 18])]\n",
      "[('election', ['recent', 'primary', 'produced', 'evidence'], ['presentments', 'manner', 'irregularities', 'evidence', 'jury', 'investigation', 'deserves', 'place']), ('produced', ['primary', 'election', 'evidence', 'irregularities'], ['said', 'thanks', 'took', 'overall', 'place', 'said', 'investigation', 'committee']), ('evidence', ['election', 'produced', 'irregularities', 'took'], ['city', 'said', 'city', 'manner', 'presentments', 'jury', 'overall', 'grand']), ('irregularities', ['produced', 'evidence', 'took', 'place'], ['election', 'deserves', 'conducted', 'charge', 'praise', 'overall', 'charge', 'deserves']), ('took', ['evidence', 'irregularities', 'place'], ['primary', 'atlanta', 'friday', 'friday', 'primary', 'primary', 'committee', 'executive']), ('place', ['irregularities', 'took'], ['said', 'produced', 'evidence', 'termend', 'jury', 'primary', 'charge', 'charge']), ('jury', ['said', 'termend'], ['county', 'jury', 'presentments', 'praise', 'executive', 'presentments', 'conducted', 'county']), ('said', ['jury', 'termend', 'presentments'], ['city', 'atlantas', 'city', 'election', 'manner', 'jury', 'jury', 'said']), ('termend', ['jury', 'said', 'presentments', 'city'], ['jury', 'manner', 'primary', 'manner', 'termend', 'election', 'friday', 'evidence']), ('presentments', ['said', 'termend', 'city', 'executive'], ['investigation', 'atlanta', 'manner', 'said', 'place', 'charge', 'irregularities', 'city'])]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "class InputData:\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "        self.normalize()\n",
    "        self.counter = 0\n",
    "        self.wordId_frequency_dict = dict()\n",
    "        self.word_count = 0  #  Number of words (repeated words only count as 1)\n",
    "        self.word_count_sum = 0  # Total number of words (the number of repeated words also accumulates)\n",
    "        self.sentence_count = 0  # Number of sentences\n",
    "        self.id2word_dict = dict()\n",
    "        self.word2id_dict = dict()\n",
    "        self._init_dict()  # Initialize the dictionary\n",
    "        self.sample_table = []\n",
    "        self._init_sample_table()\n",
    "        self.word_pairs_queue = deque()\n",
    "\n",
    "        print('Word Count is:', self.word_count)\n",
    "        print('Word Count Sum is', self.word_count_sum)\n",
    "        print('Sentence Count is:', self.sentence_count)\n",
    "\n",
    "    def normalize(self):\n",
    "      stop_words = nltk.corpus.stopwords.words('english')\n",
    "      norm_sentences_word_list = []\n",
    "      for word_list in self.sentences:\n",
    "        sentence = \" \".join(word for word in word_list)\n",
    "        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(' +', ' ', sentence)\n",
    "        sentence = sentence.strip()\n",
    "        norm_word_list = sentence.split(' ')\n",
    "        norm_word_list = [word for word in norm_word_list if word not in stop_words]\n",
    "        if(len(norm_word_list) > 1):\n",
    "          norm_sentences_word_list.append(norm_word_list)\n",
    "       \n",
    "      self.sentences = norm_sentences_word_list\n",
    "\n",
    "    def _init_dict(self):\n",
    "        word_freq = dict()\n",
    "        for word_list in self.sentences:\n",
    "            self.word_count_sum += len(word_list)\n",
    "            self.sentence_count += 1\n",
    "            for word in word_list:\n",
    "                try:\n",
    "                    word_freq[word] += 1\n",
    "                except:\n",
    "                    word_freq[word] = 1\n",
    "        word_id = 0\n",
    "        # Initialize word2id_dict, id2word_dict, wordId_frequency_dict dictionary\n",
    "        for per_word, per_count in word_freq.items():\n",
    "            self.id2word_dict[word_id] = per_word\n",
    "            self.word2id_dict[per_word] = word_id\n",
    "            self.wordId_frequency_dict[word_id] = per_count\n",
    "            word_id += 1\n",
    "        self.word_count = len(self.word2id_dict)\n",
    "\n",
    "    def _init_sample_table(self):\n",
    "        sample_table_size = 1e8\n",
    "        frequency = np.array(list(self.wordId_frequency_dict.values())) ** 0.75\n",
    "        frequency_sum = sum(frequency)\n",
    "        ratio_array = frequency / frequency_sum \n",
    "        word_count_list = np.round(ratio_array * sample_table_size)\n",
    "        for word_index, word_freq in enumerate(word_count_list):\n",
    "            self.sample_table += [word_index] * int(word_freq)  # it generates a list, the content is the id of each word, each id in the list is repeated multiple times, the number of repetitions is the word frequency\n",
    "        self.sample_table = np.array(self.sample_table)\n",
    "        print(self.sample_table.shape)\n",
    "\n",
    "    def generate_positive_pairs(self, window_size, neg_count):\n",
    "        self.counter += 1\n",
    "        if not self.sentences[20*(self.counter-1):20*self.counter]:\n",
    "            self.counter = 1\n",
    "            self.word_pairs_queue.clear()\n",
    "        sub_wids = [[self.word2id_dict[word] for word in word_list] for word_list in self.sentences[20*(self.counter-1):20*self.counter]]\n",
    "\n",
    "        \n",
    "        for words in sub_wids:\n",
    "          sentence_length = len(words)\n",
    "          for index, center_word in enumerate(words):\n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "\n",
    "            positive_words = []\n",
    "            for index_2 in range(start,end):\n",
    "              if 0 <= index_2 < sentence_length and index_2 != index:\n",
    "                positive_words.append(words[index_2])\n",
    "              elif index_2 < 0 or index_2 >= sentence_length:\n",
    "                positive_words.append(self.word_count)\n",
    "            \n",
    "            negative_words = np.random.choice(self.sample_table, size=neg_count).tolist()\n",
    "\n",
    "            self.word_pairs_queue.append((center_word, positive_words, negative_words))\n",
    "           \n",
    "\n",
    "\n",
    "    def get_batch_pairs(self, batch_size, window_size, neg_count):\n",
    "\n",
    "        while len(self.word_pairs_queue) < batch_size:\n",
    "          self.generate_positive_pairs(window_size, neg_count)              \n",
    "              \n",
    "        result_pairs = []\n",
    "        for _ in range(batch_size):\n",
    "            result_pairs.append(self.word_pairs_queue.popleft())\n",
    "        return result_pairs\n",
    "\n",
    "\n",
    "    def evaluate_pairs_count(self):\n",
    "        return self.word_count_sum\n",
    "\n",
    "\n",
    "def test():\n",
    "    sentences = brown.sents(categories=['news'])[:2]\n",
    "    test_data = InputData(sentences)\n",
    "    print(\" \".join(word for word in sentences[0]))\n",
    "    print(\" \".join(word for word in sentences[1]))\n",
    "    pos_pairs = test_data.get_batch_pairs(10, 2, 8)\n",
    "    print('positive:')\n",
    "    print(pos_pairs)\n",
    "    pos_word_pairs = []\n",
    "    for pair in pos_pairs:\n",
    "        pos_word_pairs.append((test_data.id2word_dict[pair[0]], [test_data.id2word_dict[i] for i in pair[1] if i != test_data.word_count], [test_data.id2word_dict[i] for i in pair[2] if i != test_data.word_count]))\n",
    "    print(pos_word_pairs)\n",
    "    print(len(pos_pairs))\n",
    "\n",
    "    pos_pairs = test_data.get_batch_pairs(10, 2, 8)\n",
    "    print('positive:')\n",
    "    print(pos_pairs)\n",
    "    pos_word_pairs = []\n",
    "    for pair in pos_pairs:\n",
    "        pos_word_pairs.append((test_data.id2word_dict[pair[0]], [test_data.id2word_dict[i] for i in pair[1] if i != test_data.word_count], [test_data.id2word_dict[i] for i in pair[2] if i != test_data.word_count]))\n",
    "    print(pos_word_pairs)\n",
    "    print(len(pos_pairs))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1639737228342,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "UunHC6-rZBpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, emb_size, emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.w_embeddings = nn.Embedding(emb_size, emb_dimension, sparse=True)\n",
    "        self.v_embeddings = nn.Embedding(emb_size + 1, emb_dimension, sparse=True)\n",
    "        self._init_emb()\n",
    "\n",
    "    def _init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-0, 0)\n",
    "\n",
    "    def forward(self, pos_w, pos_v, neg_v):\n",
    "        emb_w = self.w_embeddings(torch.LongTensor(pos_w))\n",
    "        emb_v = self.v_embeddings(torch.LongTensor(pos_v))\n",
    "        neg_emb_v = self.v_embeddings(torch.LongTensor(neg_v))\n",
    "\n",
    "        score = torch.mul(emb_w.unsqueeze(1), emb_v)\n",
    "        score = torch.sum(score, dim=2).squeeze()\n",
    "        score = F.logsigmoid(score)\n",
    "        score = torch.sum(score, dim=1).squeeze()\n",
    "\n",
    "        neg_score = torch.mul(emb_w.unsqueeze(1), neg_emb_v)\n",
    "        neg_score = torch.sum(neg_score, dim=2).squeeze()\n",
    "        neg_score = F.logsigmoid(-1 * neg_score)\n",
    "        neg_score = torch.sum(neg_score, dim=1).squeeze()\n",
    "\n",
    "\n",
    "        final_score = score + neg_score\n",
    "        loss = -1 * torch.sum(final_score)\n",
    "        return loss\n",
    "\n",
    "    def distance_matrix(self, word_count):\n",
    "        embedding = self.w_embeddings.weight.data.numpy()[:word_count]\n",
    "        distance_matrix = euclidean_distances(embedding)\n",
    "        return distance_matrix\n",
    "\n",
    "\n",
    "def test():\n",
    "    model = SkipGramModel(100, 10)\n",
    "    id2word = dict()\n",
    "    for i in range(100):\n",
    "        id2word[i] = str(i)\n",
    "    pos_w = [0, 2]\n",
    "    pos_v = [[9,10],[10,12]]\n",
    "    neg_v = [[23, 42, 74, 32], [32, 24, 62, 53]]\n",
    "    model.forward(pos_w, pos_v, neg_v)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1639739299505,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "z6pcTUByZP0D"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# hyper parameters\n",
    "WINDOW_SIZE = 2 \n",
    "BATCH_SIZE = 1000  # mini-batch\n",
    "EMB_DIMENSION = 100  # embedding dimension\n",
    "LR = 0.01 # Learning rate\n",
    "NEG_COUNT = 8\n",
    "\n",
    "\n",
    "class Word2Vec:\n",
    "    def __init__(self, sentences):\n",
    "        self.data = InputData(sentences)\n",
    "        self.model = SkipGramModel(self.data.word_count, EMB_DIMENSION)\n",
    "        self.lr = LR\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def train(self):\n",
    "        print(\"SkipGram Training......\")\n",
    "        pairs_count = self.data.evaluate_pairs_count()\n",
    "        print(\"pairs_count\", pairs_count)\n",
    "        batch_count = pairs_count / BATCH_SIZE\n",
    "        print(\"batch_count\", batch_count)\n",
    "        for epoch in range(1,51):\n",
    "            mean_loss = 0\n",
    "            process_bar = tqdm(range(int(batch_count)))\n",
    "            for i in process_bar:\n",
    "                pos_pairs = self.data.get_batch_pairs(BATCH_SIZE, WINDOW_SIZE, NEG_COUNT)\n",
    "                pos_w = [int(pair[0]) for pair in pos_pairs]\n",
    "                pos_v = [pair[1] for pair in pos_pairs]\n",
    "                neg_v = [pair[2] for pair in pos_pairs]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_w, pos_v, neg_v)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                mean_loss += loss\n",
    "\n",
    "            print(\"epoch:\",epoch,\"loss:\",mean_loss/int(batch_count))\n",
    "\n",
    "\n",
    "    def get_distance_matrix(self):\n",
    "        distance_matrix = self.model.distance_matrix(self.data.word_count)\n",
    "        return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12899,
     "status": "ok",
     "timestamp": 1639739317676,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "qBk19rOeBHAs",
    "outputId": "11e4eb6d-d46b-4c46-98f3-a92dc24d8a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99999555,)\n",
      "Word Count is: 24616\n",
      "Word Count Sum is 170964\n",
      "Sentence Count is: 17106\n"
     ]
    }
   ],
   "source": [
    "sentences = brown.sents(categories=['news','reviews','government','hobbies','romance'])\n",
    "w2v = Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701103,
     "status": "ok",
     "timestamp": 1639740034354,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "jIkOnp9GETIS",
    "outputId": "b6c7856b-ba5d-4880-875a-a11a9891e4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Training......\n",
      "pairs_count 170964\n",
      "batch_count 170.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(8198.7705, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss: tensor(7923.1514, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 loss: tensor(7771.2690, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 loss: tensor(7648.2461, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 loss: tensor(7530.7876, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 loss: tensor(7426.8081, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 loss: tensor(7336.6836, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss: tensor(7256.5771, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 loss: tensor(7185.5435, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 loss: tensor(7115.2905, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 loss: tensor(7045.4785, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 loss: tensor(6975.2412, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 loss: tensor(6903.3096, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 loss: tensor(6833.1528, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 loss: tensor(6760.4873, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 loss: tensor(6688.8193, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 loss: tensor(6618.3057, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 loss: tensor(6545.3223, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 loss: tensor(6472.0903, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 loss: tensor(6400.4536, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 loss: tensor(6325.2568, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 loss: tensor(6252.9956, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 loss: tensor(6173.2905, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 loss: tensor(6097.5396, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 loss: tensor(6016.7954, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 loss: tensor(5934.8726, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 loss: tensor(5850.3979, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 loss: tensor(5767.6050, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 loss: tensor(5681.5376, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 loss: tensor(5591.8013, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 loss: tensor(5505.8101, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 loss: tensor(5419.8413, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 loss: tensor(5331.1855, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 loss: tensor(5241.4663, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 loss: tensor(5150.7241, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 loss: tensor(5057.0308, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 loss: tensor(4968.7158, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 loss: tensor(4878.4702, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 loss: tensor(4788.6514, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 loss: tensor(4701.3857, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 loss: tensor(4617.2241, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 loss: tensor(4522.9956, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 loss: tensor(4443.1123, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 loss: tensor(4351.4858, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 loss: tensor(4270.9604, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:14<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 loss: tensor(4189.8584, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 loss: tensor(4110.1616, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 loss: tensor(4028.9639, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 loss: tensor(3951.3306, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:13<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 loss: tensor(3882.2522, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2v.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 18288,
     "status": "ok",
     "timestamp": 1639740416229,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "GYx4RpJkIzU_"
   },
   "outputs": [],
   "source": [
    "distance_matrix = w2v.get_distance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1639740430650,
     "user": {
      "displayName": "moghis fereidouni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjVlp_EUmsYa2wET4sH8v8ttME5Wjz5knmZivaz=s64",
      "userId": "04154357719458086941"
     },
     "user_tz": -210
    },
    "id": "TOK9m2aBI79I",
    "outputId": "2cd5e26f-538f-4017-d522-3a1b5f43a52b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': ['renting',\n",
       "  'driven',\n",
       "  'passing',\n",
       "  'driver',\n",
       "  'loaded',\n",
       "  'driving',\n",
       "  'rides',\n",
       "  'gloriana',\n",
       "  'pounds'],\n",
       " 'children': ['teach',\n",
       "  'daddy',\n",
       "  'neighbors',\n",
       "  'hundreds',\n",
       "  'fronts',\n",
       "  'relatives',\n",
       "  'loved',\n",
       "  'fortunate',\n",
       "  'helpless'],\n",
       " 'democratic': ['gubernatorial',\n",
       "  'invitation',\n",
       "  'buckley',\n",
       "  'republican',\n",
       "  'socialist',\n",
       "  'candidate',\n",
       "  'democrats',\n",
       "  'elected',\n",
       "  'statesman'],\n",
       " 'election': ['votes',\n",
       "  'defeated',\n",
       "  'ballot',\n",
       "  'bush',\n",
       "  'socialist',\n",
       "  'gubernatorial',\n",
       "  'contention',\n",
       "  'bradley',\n",
       "  'algol'],\n",
       " 'football': ['teen',\n",
       "  'clubs',\n",
       "  'cincinnati',\n",
       "  'champions',\n",
       "  'miami',\n",
       "  'buffalo',\n",
       "  'minnesota',\n",
       "  'presents',\n",
       "  'basketball'],\n",
       " 'game': ['longhorns',\n",
       "  'lewisohn',\n",
       "  'stadium',\n",
       "  'eighth',\n",
       "  'begun',\n",
       "  'playoff',\n",
       "  'pitching',\n",
       "  'knee',\n",
       "  'weve'],\n",
       " 'mettwurst': ['bratwurst',\n",
       "  'bologna',\n",
       "  'psyche',\n",
       "  'blacking',\n",
       "  'depressants',\n",
       "  'bockwurst',\n",
       "  'rodneymiss',\n",
       "  'copland',\n",
       "  'stares'],\n",
       " 'sauce': ['tablespoon',\n",
       "  'mustard',\n",
       "  'tablespoons',\n",
       "  'worcestershire',\n",
       "  'teaspoon',\n",
       "  'chili',\n",
       "  'pineapple',\n",
       "  'teaspoons',\n",
       "  'paste'],\n",
       " 'tablespoon': ['teaspoons',\n",
       "  'worcestershire',\n",
       "  'teaspoon',\n",
       "  'vinegar',\n",
       "  'sweetsour',\n",
       "  'chili',\n",
       "  'sauerkraut',\n",
       "  'tablespoons',\n",
       "  'melted'],\n",
       " 'university': ['carleton',\n",
       "  'awarded',\n",
       "  'emory',\n",
       "  'professional',\n",
       "  'institute',\n",
       "  'physics',\n",
       "  'graduate',\n",
       "  'hunter',\n",
       "  'magazine']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words = {search_term: [w2v.data.id2word_dict[idx] for idx in distance_matrix[w2v.data.word2id_dict[search_term]].argsort()[1:10]] \n",
    "                   for search_term in ['tablespoon','election','sauce', 'democratic','game','children','mettwurst','car','football','university']}\n",
    "similar_words"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZcB4r+1H4Yhvbm1P9zR0i",
   "collapsed_sections": [],
   "name": "Word2Vec - skipGram with negative sampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
